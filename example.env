# Example .env file for Personal Brain
# Copy this file to .env and fill in your values

#====================#
# NODE CONFIGURATION #
#====================#
NODE_ENV=development # Set to 'production' in production environments

#=================#
# LOG SETTINGS    #
#=================#
# Log levels: error, warn, info, debug
LOG_CONSOLE_LEVEL=debug  # Console output level
LOG_FILE_LEVEL=debug     # File logging level

# Log file paths (relative to project root)
ERROR_LOG_PATH=logs/error.log
COMBINED_LOG_PATH=logs/combined.log
DEBUG_LOG_PATH=logs/debug.log

#=================#
# AI MODELS       #
#=================#
# OpenAI Configuration (for embeddings)
OPENAI_API_KEY=your-openai-api-key-here
OPENAI_EMBEDDING_MODEL=text-embedding-3-small # Embedding model to use
OPENAI_EMBEDDING_DIMENSION=1536 # Dimension size for the embeddings
OPENAI_BATCH_SIZE=10 # Number of documents to embed in one API call
OPENAI_CHUNK_SIZE=512 # Size of text chunks for embedding
OPENAI_CHUNK_OVERLAP=100 # Overlap between chunks for better context

# Anthropic Configuration (for conversational AI)
ANTHROPIC_API_KEY=your-anthropic-api-key-here 
ANTHROPIC_MODEL=claude-3-7-sonnet-20250219 # Claude model to use
ANTHROPIC_MAX_TOKENS=1000 # Max tokens in response
ANTHROPIC_TEMPERATURE=0.0 # 0.0 for deterministic responses, higher for more creativity

#=================#
# TEXT PROCESSING #
#=================#
# Text chunking parameters
DEFAULT_CHUNK_SIZE=512
DEFAULT_CHUNK_OVERLAP=100
DEFAULT_CHUNK_THRESHOLD=1000

# Tag extraction settings
TAG_CONTENT_MAX_LENGTH=10000 # Max content length for tag extraction
DEFAULT_MAX_TAGS=7 # Maximum number of tags to extract
DEFAULT_MAX_KEYWORDS=10 # Maximum number of keywords to extract

# Reading time estimation
DEFAULT_WORDS_PER_MINUTE=200 # Average reading speed

#=================#
# EXTERNAL APIs   #
#=================#
# Wikipedia API
WIKIPEDIA_API_URL=https://en.wikipedia.org/w/api.php
WIKIPEDIA_USER_AGENT=PersonalBrain/1.0 (personal use)

# News API
NEWS_API_KEY=your-news-api-key-here
NEWS_API_URL=https://newsapi.org/v2
NEWS_API_MAX_AGE_HOURS=168 # 1 week

#=================#
# PATHS & FILES   #
#=================#
# Application paths
PROFILES_PATH=./src/models/profiles
IMPORT_PATH=./articles

# Database configuration
DB_PATH=./brain.db

#=================#
# SERVER SETTINGS #
#=================#
# HTTP server port for MCP (Model-Control-Protocol)
MCP_PORT=8080

#=================#
# CONVERSATION    #
#=================#
# Default room ID for CLI conversations
DEFAULT_CLI_ROOM_ID=cli-default-room

#=================#
# WEBSITE CONFIG  #
#=================#
# Basic site information
WEBSITE_TITLE=Personal Brain
WEBSITE_DESCRIPTION=My personal website powered by Personal Brain
WEBSITE_AUTHOR=Your Name
WEBSITE_BASE_URL=http://localhost:4321

# Project structure
WEBSITE_PROJECT_PATH=./src/website

# Deployment provider
# Options: 'local', 'netlify', 'github'
WEBSITE_DEPLOYMENT_PROVIDER=netlify

#=================#
# NETLIFY DEPLOY  #
#=================#
# Get your token from Netlify user settings > Applications > Personal access tokens
NETLIFY_TOKEN=your-netlify-personal-access-token

# If you have an existing site, provide its ID
# If not, a new site will be created with NETLIFY_SITE_NAME
NETLIFY_SITE_ID=your-site-id

# The name for a new site (only used if NETLIFY_SITE_ID is not provided)
NETLIFY_SITE_NAME=your-personal-brain-site

# Optional team name or ID if you're using a team account
NETLIFY_TEAM=

# Build directory relative to the Astro project (usually 'dist')
NETLIFY_BUILD_DIR=dist

#=================#
# GITHUB DEPLOY   #
#=================#
# GitHub personal access token with repo scope
GITHUB_TOKEN=your-github-personal-access-token

# Repository in format 'username/repo-name'
GITHUB_REPOSITORY=username/personal-brain-website

# Branch to deploy to (usually 'gh-pages')
GITHUB_BRANCH=gh-pages

#===================#
# TESTING SETTINGS  #
#===================#
# Set to '1' to enable integration tests that would otherwise be skipped
ENABLE_INTEGRATION_TESTS=0